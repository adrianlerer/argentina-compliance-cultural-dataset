#!/usr/bin/env python3
"""
Argentina Cultural Compliance Classifier - Community Edition
Open Source classifier for Argentina cultural compliance phrases

License: MIT
Author: IntegriDAI Argentina
Purpose: Cultural sovereignty for Ley 27.401 compliance
Version: 1.0-community (Validated by GPT-5, Claude, Gemini, Qwen3)
"""

import json
import re
import logging
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path
import unicodedata

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ComplianceResult:
    """Result of cultural compliance classification"""
    phrase: str
    risk_level: int  # 1-5 scale
    category: str
    cultural_markers: List[str]
    legal_reference: str
    explanation: str
    competitive_advantage: str
    confidence_score: float
    ai_validation: str

class ArgentinaComplianceClassifier:
    """
    Community edition classifier for Argentina cultural compliance phrases
    
    Features:
    - 20 validated cultural phrases
    - 8 risk categories mapped to Ley 27.401
    - 6 cultural markers detection
    - Validated by 4 AI systems (97% consensus)
    """
    
    def __init__(self, dataset_path: str = "dataset/frases_culturales_community.json"):
        """
        Initialize classifier with community dataset
        
        Args:
            dataset_path: Path to the community dataset JSON file
        """
        self.dataset_path = Path(dataset_path)
        self.phrases_data = {}
        self.cultural_markers = {}
        self.risk_categories = {}
        
        # Load community dataset
        self._load_dataset()
        self._build_patterns()
        
        logger.info(f"Argentina Compliance Classifier initialized")
        logger.info(f"Dataset: {len(self.phrases_data)} validated phrases")
        logger.info(f"AI Validation: 97% consensus (GPT-5, Claude, Gemini, Qwen3)")
    
    def _load_dataset(self):
        """Load the community dataset"""
        try:
            with open(self.dataset_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # Extract dataset information
            self.dataset_info = data.get('dataset_info', {})
            self.validation_summary = data.get('validation_summary', {})
            self.taxonomy = data.get('taxonomy', {})
            
            # Process phrases
            for phrase_data in data.get('phrases', []):
                phrase_id = phrase_data['id']
                self.phrases_data[phrase_id] = phrase_data
            
            # Extract taxonomies
            self.cultural_markers = self.taxonomy.get('cultural_markers', {})
            self.risk_categories = self.taxonomy.get('risk_categories', {})
            
            logger.info(f"Community dataset loaded: v{self.dataset_info.get('version')}")
            
        except FileNotFoundError:
            logger.error(f"Dataset not found: {self.dataset_path}")
            raise
        except json.JSONDecodeError as e:
            logger.error(f"Error parsing dataset JSON: {e}")
            raise
    
    def _build_patterns(self):
        """Build regex patterns for cultural marker detection"""
        
        # Argentine diminutives pattern
        self.diminutivos_pattern = re.compile(
            r'\b\w+(ito|ita|cito|cita|illo|illa)\b', 
            re.IGNORECASE
        )
        
        # Extended family pattern  
        self.familia_pattern = re.compile(
            r'\b(hermano|hermana|cuÃ±ado|cuÃ±ada|primo|prima|tÃ­o|tÃ­a|suegro|suegra|sobrino|sobrina)\b',
            re.IGNORECASE
        )
        
        # Local euphemisms
        self.eufemismo_pattern = re.compile(
            r'\b(regalito|asadito|consultorÃ­a|viÃ¡ticos|gestionar|arreglar|acomodar|llegada|seÃ±a)\b',
            re.IGNORECASE
        )
        
        # Argentine informality
        self.informalidad_pattern = re.compile(
            r'\b(dale|che|tranquilo|pibe|piola|bÃ¡rbaro|copado)\b',
            re.IGNORECASE
        )
        
        # Cultural minimization
        self.minimizacion_pattern = re.compile(
            r'\b(no pasa nada|siempre|es normal|solo|nomÃ¡s|tranquilo)\b',
            re.IGNORECASE
        )
        
        # Argentine traditions
        self.tradicion_pattern = re.compile(
            r'\b(asado|mate|club|parrilla)\b',
            re.IGNORECASE
        )
    
    def extract_cultural_markers(self, text: str) -> List[str]:
        """Extract Argentine cultural markers from text"""
        markers = []
        text_lower = text.lower()
        
        # Check for diminutives
        if self.diminutivos_pattern.search(text):
            markers.append('diminutivo_argentino')
        
        # Check for extended family
        if self.familia_pattern.search(text):
            markers.append('familia_extendida')
        
        # Check for local euphemisms
        if self.eufemismo_pattern.search(text):
            markers.append('eufemismo_local')
        
        # Check for informality
        if self.informalidad_pattern.search(text):
            markers.append('informalidad_linguistica')
        
        # Check for minimization
        if self.minimizacion_pattern.search(text):
            markers.append('minimizacion_cultural')
        
        # Check for traditions
        if self.tradicion_pattern.search(text):
            markers.append('tradicion_argentina')
        
        return markers
    
    def calculate_risk_score(self, text: str, cultural_markers: List[str]) -> Tuple[int, float]:
        """Calculate risk score based on patterns and markers"""
        base_risk = 1
        confidence = 0.5
        text_lower = text.lower()
        
        # Check for exact phrase matches first
        for phrase_data in self.phrases_data.values():
            phrase = phrase_data.get('phrase', '').lower()
            if phrase in text_lower or text_lower in phrase:
                return phrase_data.get('risk_level', 1), 0.95
        
        # Risk assessment by cultural markers
        risk_weights = {
            'diminutivo_argentino': 1.2,
            'familia_extendida': 1.5,
            'eufemismo_local': 1.8,
            'informalidad_linguistica': 1.1,
            'minimizacion_cultural': 1.3,
            'tradicion_argentina': 1.2
        }
        
        for marker in cultural_markers:
            if marker in risk_weights:
                base_risk = min(5, base_risk * risk_weights[marker])
                confidence += 0.1
        
        # High-risk keywords
        high_risk_terms = {
            'inspector': 2.5,
            'funcionario': 2.0,
            'regalito': 2.5,
            'consultorÃ­a': 2.0,
            'viÃ¡ticos': 1.8,
            'por izquierda': 2.5,
            'cuÃ±ado': 2.0,
            'hermano': 2.2,
            'arreglar': 1.5
        }
        
        for term, multiplier in high_risk_terms.items():
            if term in text_lower:
                base_risk = min(5, base_risk * multiplier)
                confidence += 0.15
        
        return min(5, round(base_risk)), min(1.0, confidence)
    
    def predict_category(self, text: str) -> Tuple[str, str]:
        """Predict risk category based on content"""
        text_lower = text.lower()
        
        # Pattern matching for categories
        if any(term in text_lower for term in ['regalito', 'inspector', 'funcionario', 'seÃ±a', 'agilizar']):
            return 'SOBORNO', self.risk_categories.get('SOBORNO', 'Soborno')
        elif any(term in text_lower for term in ['asadito', 'mate', 'club', 'hospitalidad']):
            return 'GASTOS_EXCESIVOS', self.risk_categories.get('GASTOS_EXCESIVOS', 'Gastos Excesivos')
        elif any(term in text_lower for term in ['cuÃ±ado', 'hermano', 'primo', 'familia']):
            return 'CONFLICTO_INTERES', self.risk_categories.get('CONFLICTO_INTERES', 'Conflicto InterÃ©s')
        elif any(term in text_lower for term in ['viÃ¡ticos', 'gastos', 'cargalo']):
            return 'FRAUDE_GASTOS', self.risk_categories.get('FRAUDE_GASTOS', 'Fraude Gastos')
        elif any(term in text_lower for term in ['contacto', 'llegada', 'influencia', 'hablar con']):
            return 'TRAFICO_INFLUENCIAS', self.risk_categories.get('TRAFICO_INFLUENCIAS', 'TrÃ¡fico Influencias')
        elif any(term in text_lower for term in ['facturar', 'consultorÃ­a', 'papeles']):
            return 'FRAUDE_FISCAL', self.risk_categories.get('FRAUDE_FISCAL', 'Fraude Fiscal')
        elif any(term in text_lower for term in ['por izquierda', 'arreglar', 'gestionar']):
            return 'ACCION_CLANDESTINA', self.risk_categories.get('ACCION_CLANDESTINA', 'AcciÃ³n Clandestina')
        else:
            return 'CULTURA_RIESGO', self.risk_categories.get('CULTURA_RIESGO', 'Cultura Riesgo')
    
    def get_competitive_advantage(self, text: str) -> str:
        """Get competitive advantage explanation for the phrase"""
        text_lower = text.lower()
        
        # Check for exact matches first
        for phrase_data in self.phrases_data.values():
            phrase = phrase_data.get('phrase', '').lower()
            if phrase in text_lower:
                return phrase_data.get('competitive_advantage', 
                    'Herramientas internacionales no detectan matices culturales argentinos')
        
        # Generic advantages by pattern
        if 'regalito' in text_lower:
            return 'Herramientas internacionales interpretan como "small gift" - Dataset lo marca como soborno crÃ­tico'
        elif 'por izquierda' in text_lower:
            return 'Sin traducciÃ³n literal - Herramientas internacionales: falso negativo garantizado'
        elif 'cuÃ±ado' in text_lower or 'hermano' in text_lower:
            return 'Peso cultural de lazos familiares no comprendido por sistemas internacionales'
        else:
            return 'Dataset local detecta matices culturales que herramientas genÃ©ricas no pueden identificar'
    
    def classify(self, text: str) -> ComplianceResult:
        """
        Classify text for compliance risks using Argentine cultural patterns
        
        Args:
            text: Text to analyze for compliance risks
            
        Returns:
            ComplianceResult with risk assessment and cultural analysis
        """
        # Normalize text
        normalized_text = unicodedata.normalize('NFKD', text)
        
        # Extract cultural markers
        cultural_markers = self.extract_cultural_markers(text)
        
        # Calculate risk
        risk_level, confidence_score = self.calculate_risk_score(text, cultural_markers)
        
        # Predict category
        category_code, category_name = self.predict_category(text)
        
        # Get competitive advantage
        competitive_advantage = self.get_competitive_advantage(text)
        
        # Find exact match data if available
        explanation = "AnÃ¡lisis basado en patrones culturales argentinos"
        legal_reference = category_name
        ai_validation = f"Consenso multi-IA: {self.validation_summary.get('multi_ia_consensus', 0.97):.0%}"
        
        for phrase_data in self.phrases_data.values():
            if phrase_data.get('phrase', '').lower() in text.lower():
                explanation = phrase_data.get('explanation', explanation)
                legal_reference = phrase_data.get('legal_reference', legal_reference)
                ai_validation = phrase_data.get('ai_validation', ai_validation)
                break
        
        return ComplianceResult(
            phrase=text,
            risk_level=risk_level,
            category=category_code,
            cultural_markers=cultural_markers,
            legal_reference=legal_reference,
            explanation=explanation,
            competitive_advantage=competitive_advantage,
            confidence_score=confidence_score,
            ai_validation=ai_validation
        )
    
    def classify_batch(self, texts: List[str]) -> List[ComplianceResult]:
        """Classify multiple texts in batch"""
        results = []
        for text in texts:
            try:
                result = self.classify(text)
                results.append(result)
            except Exception as e:
                logger.error(f"Error classifying '{text}': {e}")
        return results
    
    def get_stats(self) -> Dict[str, Any]:
        """Get classifier statistics"""
        return {
            'dataset_version': self.dataset_info.get('version'),
            'total_phrases': len(self.phrases_data),
            'validation_status': self.dataset_info.get('validation_status'),
            'ai_consensus': self.validation_summary.get('multi_ia_consensus'),
            'cultural_markers': len(self.cultural_markers),
            'risk_categories': len(self.risk_categories),
            'license': self.dataset_info.get('license')
        }

def classify(text: str) -> ComplianceResult:
    """Quick classification function"""
    classifier = ArgentinaComplianceClassifier()
    return classifier.classify(text)

def classify_batch(texts: List[str]) -> List[ComplianceResult]:
    """Quick batch classification function"""
    classifier = ArgentinaComplianceClassifier()
    return classifier.classify_batch(texts)

if __name__ == "__main__":
    # Demo execution
    print("ğŸ‡¦ğŸ‡· Argentina Cultural Compliance Classifier - Community Edition")
    print("Validado por GPT-5, Claude, Gemini y Qwen3 | 97% Consenso")
    print("=" * 70)
    
    # Initialize classifier
    classifier = ArgentinaComplianceClassifier()
    
    # Demo phrases
    demo_phrases = [
        "Es solo un asadito con el cliente",
        "Un regalito para el inspector", 
        "Mi cuÃ±ado tiene una empresa",
        "Facturamos como consultorÃ­a",
        "Lo arreglamos por izquierda",
        "Dale que siempre se hizo asÃ­"
    ]
    
    print(f"\nğŸ“Š DEMO - AnÃ¡lisis de {len(demo_phrases)} frases culturales argentinas:\n")
    
    for i, phrase in enumerate(demo_phrases, 1):
        result = classifier.classify(phrase)
        
        print(f"[{i}] \"{phrase}\"")
        print(f"    ğŸ¯ Riesgo: {result.risk_level}/5 ({result.confidence_score:.0%} confianza)")
        print(f"    ğŸ“‚ CategorÃ­a: {result.category}")
        print(f"    âš–ï¸  Legal: {result.legal_reference}")
        print(f"    ğŸ‡¦ğŸ‡· Marcadores: {', '.join(result.cultural_markers) if result.cultural_markers else 'Ninguno'}")
        print(f"    ğŸš€ Ventaja: {result.competitive_advantage[:80]}...")
        print()
    
    # Show stats
    stats = classifier.get_stats()
    print(f"ğŸ“ˆ ESTADÃSTICAS:")
    print(f"   Dataset: v{stats['dataset_version']} ({stats['total_phrases']} frases)")
    print(f"   ValidaciÃ³n: {stats['validation_status']}")
    print(f"   Consenso IA: {stats['ai_consensus']:.0%}")
    print(f"   Licencia: {stats['license']}")
    
    print(f"\nâœ… Â¿Tu empresa puede detectar estos riesgos culturales?")
    print(f"ğŸš€ PrÃ³ximos pasos: pip install argentina-compliance-dataset")
    print(f"ğŸ’¼ Enterprise: enterprise@integridai.com.ar")